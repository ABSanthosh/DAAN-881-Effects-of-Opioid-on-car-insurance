{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "051a1f75-bb15-4bab-92f3-4c0c4a034089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d28588e-2f33-4f9c-8d97-577eb0d678ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "BASE_PATH = \"C:/Users/jason/OneDrive - The Pennsylvania State University/DAAN 881, Data Drive Decision Making/Project/Auto Data/Merged/\"\n",
    "SC_FILE = \"sc_cleaned_combined_2013_2022.csv\"\n",
    "TN_FILE = \"TN_PROCESSED_corrected_v2.csv\"\n",
    "PA_FILE = \"PA_PROCESSED_corrected.csv\"\n",
    "FARS_FILE = \"FARS_combined_cleaned_2013-2023_v2.csv\"\n",
    "\n",
    "SAVE_MERGED_FILE = True\n",
    "MERGED_FILE_NAME = \"merged_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a98db8-305b-4d92-b5d7-3206abc1e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as merged_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADING\n",
    "def load_dataset(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return pd.read_csv(filepath, dtype=str)\n",
    "    else:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "\n",
    "# Load datasets\n",
    "sc_df = load_dataset(os.path.join(BASE_PATH, SC_FILE))\n",
    "tn_df = load_dataset(os.path.join(BASE_PATH, TN_FILE))\n",
    "pa_df = load_dataset(os.path.join(BASE_PATH, PA_FILE))\n",
    "fars_df = load_dataset(os.path.join(BASE_PATH, FARS_FILE))\n",
    "\n",
    "# Merge SC + TN + PA\n",
    "merged_df = pd.concat([df for df in [sc_df, tn_df, pa_df] if df is not None], ignore_index=True)\n",
    "if SAVE_MERGED_FILE:\n",
    "    merged_df.to_csv(os.path.join(BASE_PATH, MERGED_FILE_NAME), index=False)\n",
    "    print(f\"Merged dataset saved as {MERGED_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ec05dd-eb9a-4c31-81f2-8dfe5a9dc4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREP\n",
    "def preprocess(df):\n",
    "    df[\"crash_date\"] = pd.to_datetime(df[\"crash_date\"], errors=\"coerce\")\n",
    "    df[\"severity_level\"] = pd.to_numeric(df[\"severity_level\"], errors=\"coerce\")\n",
    "    df[\"driver_age\"] = pd.to_numeric(df[\"driver_age\"], errors=\"coerce\")\n",
    "    df[\"opioid_flag\"] = pd.to_numeric(df[\"opioid_flag\"], errors=\"coerce\")\n",
    "    df[\"alcohol_flag\"] = pd.to_numeric(df[\"alcohol_flag\"], errors=\"coerce\")\n",
    "    df[\"any_drug_flag\"] = pd.to_numeric(df[\"any_drug_flag\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "merged_df = preprocess(merged_df)\n",
    "fars_df = preprocess(fars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836044a7-e04b-41e0-aac6-3c580d729d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation before modeling\n",
    "\n",
    "#for feature in ['driver_age', 'alcohol_flag', 'any_drug_flag']:\n",
    "#    if feature in train_df.columns:\n",
    "#        missing_count = train_df[feature].isna().sum()\n",
    "#        print(f\"Missing {feature} in training set: {missing_count}\")\n",
    "        \n",
    "#        if missing_count > 0:\n",
    "#            if feature == 'driver_age':\n",
    "#                median_age = train_df['driver_age'].median()\n",
    "#                train_df['driver_age'] = train_df['driver_age'].fillna(median_age)\n",
    "#                test_df['driver_age'] = test_df['driver_age'].fillna(median_age)\n",
    "#            else:\n",
    "#                train_df[feature] = train_df[feature].fillna(0)\n",
    "#                test_df[feature] = test_df[feature].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2de33ed-cc6a-4178-9084-e36481794036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in TEST MODE: Using only 5% of the data.\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE 5% TEST MODE (for safe testing first)\n",
    "TEST_MODE = True\n",
    "if TEST_MODE:\n",
    "    merged_df = merged_df.sample(frac=0.05, random_state=42)\n",
    "    fars_df = fars_df.sample(frac=0.05, random_state=42)\n",
    "    print(\"Running in TEST MODE: Using only 5% of the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47c53837-34f1-409c-a130-0fa339421933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING\n",
    "def split_data(df):\n",
    "    df = df.sort_values('crash_date')\n",
    "    train = df[(df['crash_date'].dt.year >= 2013) & (df['crash_date'].dt.year <= 2020)]\n",
    "    valid = df[(df['crash_date'].dt.year == 2021)]\n",
    "    test  = df[(df['crash_date'].dt.year == 2022)]\n",
    "    return train, valid, test\n",
    "\n",
    "train_df, valid_df, test_df = split_data(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "329d960d-db72-4d8c-a3b5-b6a0e8ceec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression for Opioid Prediction ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     58568\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           1.00     58579\n",
      "   macro avg       0.50      0.50      0.50     58579\n",
      "weighted avg       1.00      1.00      1.00     58579\n",
      "\n",
      "ROC-AUC: 0.7110289826278079\n"
     ]
    }
   ],
   "source": [
    "# BASELINE MODEL (Logistic Regression for Opioid Prediction)\n",
    "def baseline_logistic(train_df, test_df):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    X_train = train_df[['driver_age', 'alcohol_flag', 'any_drug_flag']]\n",
    "    y_train = train_df['opioid_flag']\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[['driver_age', 'alcohol_flag', 'any_drug_flag']]\n",
    "    y_test = test_df['opioid_flag']\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Logistic Regression for Opioid Prediction ===\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
    "\n",
    "baseline_logistic(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a97ac23-9930-4162-879c-f8ce66a96324",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, preds))\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rf, X_test\n\u001b[1;32m---> 20\u001b[0m rf_model, rf_X_test \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_forest_smote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m, in \u001b[0;36mrandom_forest_smote\u001b[1;34m(train_df, test_df)\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m train_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriver_age\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malcohol_flag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124many_drug_flag\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseverity_level\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      9\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_res, y_res)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepL\\lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepL\\lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepL\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    392\u001b[0m )\n\u001b[0;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepL\\lib\\site-packages\\sklearn\\neighbors\\_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     )\n\u001b[0;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST WITH SMOTE FOR SEVERITY\n",
    "def random_forest_smote(train_df, test_df):\n",
    "    smote = SMOTE()\n",
    "    X_train = train_df[['driver_age', 'alcohol_flag', 'any_drug_flag']]\n",
    "    y_train = train_df['severity_level']\n",
    "    X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_res, y_res)\n",
    "\n",
    "    X_test = test_df[['driver_age', 'alcohol_flag', 'any_drug_flag']]\n",
    "    y_test = test_df['severity_level']\n",
    "    preds = rf.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Random Forest with SMOTE for Severity ===\")\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    return rf, X_test\n",
    "\n",
    "rf_model, rf_X_test = random_forest_smote(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf395e-de4f-4f54-b7ac-7524ac2d7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP for Interpretability\n",
    "def shap_explainer(model, X_test):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "shap_explainer(rf_model, rf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29735687-8713-47c0-b6f6-af24e62f7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for Dimensionality Validation\n",
    "def pca_analysis(df):\n",
    "    features = ['driver_age', 'opioid_flag', 'alcohol_flag', 'any_drug_flag', 'fatalities', 'injuries']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df[features].fillna(0))\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(X_scaled)\n",
    "\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "    plt.title('PCA Scree Plot')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "pca_analysis(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d6b05-5f75-4ea3-9cab-7fb5590b0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRESCRIPTIVE RECOMMENDATION ENGINE\n",
    "def prescriptive_analysis(df):\n",
    "    df['high_risk_driver'] = ((df['opioid_flag'] == 1) | (df['alcohol_flag'] == 1) | (df['driver_age'] < 21) | (df['driver_age'] > 70)).astype(int)\n",
    "\n",
    "    risk_summary = df.groupby('county_fips')['high_risk_driver'].mean().sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    risk_summary.head(20).plot(kind='barh')\n",
    "    plt.title('Top 20 Counties by High Risk Driver Rates')\n",
    "    plt.xlabel('Proportion of High-Risk Drivers')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "prescriptive_analysis(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8c68f-7689-47b9-8e99-fee2d1007139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FARS side-by-side\n",
    "print(\"\\n\\n=============\\nRunning Same Pipelines on FARS\\n=============\")\n",
    "train_fars, valid_fars, test_fars = split_data(fars_df)\n",
    "baseline_logistic(train_fars, test_fars)\n",
    "rf_model_fars, rf_X_test_fars = random_forest_smote(train_fars, test_fars)\n",
    "shap_explainer(rf_model_fars, rf_X_test_fars)\n",
    "pca_analysis(fars_df)\n",
    "prescriptive_analysis(fars_df)\n",
    "\n",
    "print(\"\\n\\nALL FINAL SCRIPTS COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03e649-9225-47e7-b25d-b9dd2c1f89f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
