{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2b0f5d-2d21-4ccb-9ba9-f37dfdef85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1665534a-16fb-409d-b01a-daaf19f92a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input CSV file: C:/Users/jason/OneDrive - The Pennsylvania State University/DAAN 881, Data Drive Decision Making/Project/Auto Data/Merged/PA_PROCESSED_corrected.csv\n",
      "Output Excel file (multi-sheet): C:/Users/jason/OneDrive - The Pennsylvania State University/DAAN 881, Data Drive Decision Making/Project/Auto Data/Merged/PA_PROCESSED_corrected_multi_sheet.xlsx\n",
      "Max rows per sheet: 1,000,000\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "file_directory = r\"C:/Users/jason/OneDrive - The Pennsylvania State University/DAAN 881, Data Drive Decision Making/Project/Auto Data/Merged/\"\n",
    "csv_filename = \"PA_PROCESSED_corrected.csv\"\n",
    "excel_filename = \"PA_PROCESSED_corrected_multi_sheet.xlsx\" # Changed name slightly\n",
    "\n",
    "csv_filepath = os.path.join(file_directory, csv_filename)\n",
    "excel_filepath = os.path.join(file_directory, excel_filename)\n",
    "\n",
    "# Define max rows per Excel sheet (slightly less than the limit for safety)\n",
    "max_rows_per_sheet = 1000000\n",
    "\n",
    "print(f\"Input CSV file: {csv_filepath}\")\n",
    "print(f\"Output Excel file (multi-sheet): {excel_filepath}\")\n",
    "print(f\"Max rows per sheet: {max_rows_per_sheet:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31bb460-545e-494d-b266-45950a9548df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading 'PA_PROCESSED_corrected.csv'...\n",
      "Successfully read 5,538,978 rows and 15 columns.\n",
      "\n",
      "Writing data to multiple sheets in 'PA_PROCESSED_corrected_multi_sheet.xlsx'...\n",
      "Data will be split into 6 sheet(s).\n",
      "  Writing sheet 'Data_Part_1' (rows 1 to 1,000,000)...\n",
      "  Writing sheet 'Data_Part_2' (rows 1,000,001 to 2,000,000)...\n",
      "  Writing sheet 'Data_Part_3' (rows 2,000,001 to 3,000,000)...\n",
      "  Writing sheet 'Data_Part_4' (rows 3,000,001 to 4,000,000)...\n",
      "  Writing sheet 'Data_Part_5' (rows 4,000,001 to 5,000,000)...\n",
      "  Writing sheet 'Data_Part_6' (rows 5,000,001 to 5,538,978)...\n",
      "\n",
      "Successfully wrote 6 sheets to 'C:/Users/jason/OneDrive - The Pennsylvania State University/DAAN 881, Data Drive Decision Making/Project/Auto Data/Merged/PA_PROCESSED_corrected_multi_sheet.xlsx'.\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Read CSV ---\n",
    "try:\n",
    "    print(f\"\\nReading '{csv_filename}'...\")\n",
    "    # It might be beneficial to read in chunks if memory is also an issue,\n",
    "    # but for now, let's read the whole thing first if possible.\n",
    "    df = pd.read_csv(csv_filepath, low_memory=False)\n",
    "    total_rows = len(df)\n",
    "    print(f\"Successfully read {total_rows:,} rows and {len(df.columns)} columns.\")\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"CSV file is empty. No Excel file will be created.\")\n",
    "        exit()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Input file not found at '{csv_filepath}'. Please check the path and filename.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: An error occurred while reading the CSV file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Write to Excel (Multiple Sheets) ---\n",
    "try:\n",
    "    print(f\"\\nWriting data to multiple sheets in '{excel_filename}'...\")\n",
    "    # Calculate the number of sheets needed\n",
    "    num_sheets = math.ceil(total_rows / max_rows_per_sheet)\n",
    "    print(f\"Data will be split into {num_sheets} sheet(s).\")\n",
    "\n",
    "    # Use ExcelWriter to write to the same file\n",
    "    with pd.ExcelWriter(excel_filepath, engine='openpyxl') as writer:\n",
    "        for i in range(num_sheets):\n",
    "            start_row = i * max_rows_per_sheet\n",
    "            end_row = min((i + 1) * max_rows_per_sheet, total_rows)\n",
    "            sheet_name = f'Data_Part_{i+1}'\n",
    "\n",
    "            print(f\"  Writing sheet '{sheet_name}' (rows {start_row+1:,} to {end_row:,})...\")\n",
    "\n",
    "            # Select the chunk of the DataFrame\n",
    "            df_chunk = df.iloc[start_row:end_row]\n",
    "\n",
    "            # Write the chunk to the current sheet\n",
    "            df_chunk.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"\\nSuccessfully wrote {num_sheets} sheets to '{excel_filepath}'.\")\n",
    "\n",
    "except ImportError:\n",
    "     print(\"\\nERROR: The 'openpyxl' library is required to write Excel files.\")\n",
    "     print(\"Please install it using: pip install openpyxl\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: An error occurred while writing the Excel file: {e}\")\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67b653-8393-4bb1-9cfa-7f7d0c71fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
